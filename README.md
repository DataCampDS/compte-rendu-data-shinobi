# suivi-datacamp
Les points hebdomadaires se feront sur ce README.md

# Week 1 & 2 tasks:

We have discussed about the workflow of this project by divided for each members tasks to ensure steady progress. We started with Exploratory Data Analysis (Descriptive Statistics,...), and Data Preprocessing. This step is important because it helps us clearly understand the nature of the data and gives us an initial direction for improving performance along the way.

After that, we moved on to feature engineering (normalization, standard scaler, PCA), and now we are experimenting with baseline classification models such as Logistic Regression, Random Forest, KNN, XGBoost, etc. Here, we are trying every model's setup as many as possible that could give us a good performance with minimal time run.  

Following these steps, we will proceed to work on deep learning models if needed.

Ratanakmuny:
- Exploratory Data Analysis
- Data preprocessing
  
Kimmeng:
- Data preprocessing (log normalization)
- Feature Engineering (Standard Scaler, PCA)
- Train and test Logistics Regression

Tito:
- Data preprocessing (normalization)
- Feature Engineering (Standard Scaler, PCA)
- Train and test Random Forest Regression

# Week 3 & 4 tasks:

These two weeks due to many tasks of project from other courses, our progress is a little bit slow. In this stage, we are still working on the modeling by exploring all the possible models that we know and from the assumption that from did EDA. From the modeling that we have done, the accuracy of the baseline model seems to be around 0.8 on the test dataset. 

So, we are working on training new models, apply feature engineerings to see whether the accuracy can be achived higher than the result we have or not.

Our purpose is to find serveral best performance models then try to apply the feature engineering and hyperparamter in the next stage. 

The tasks were divided:

Ratanakmuny:
- Data Preprocessing (Stull working on it because the result didn't improve like what we expected it to be)
- Worked on handle the imbalanced class with SMOTE
- Trained on Logistic, Random Forest, SVM and Gradient Boosting

Kimmeng & Tito:
- Research on High Variance Gene Selection
- Perform High Variance Gene selection
- Encounter overfitting problem when doing this
